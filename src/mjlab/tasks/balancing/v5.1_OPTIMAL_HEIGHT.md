# v5.1: Optimal Height Range + Longer Episodes

## User Feedback

1. **Feet moving too high**: Robot was lifting knee excessively, causing instability
2. **Episodes too short**: Robot falling before `fell_over` termination triggers

## Changes Made

### 1. Episode Length: 20s → 40s (2x longer)

```python
episode_length_s: float = 40.0  # Was 20.0
```

**Why**: 
- Gives robot time to reach and maintain stable single-leg position
- Ensures terminations trigger properly if robot falls
- Allows `balanced_stance_duration` reward to accumulate meaningfully

**Impact**:
- Max steps: 1000 → 2000
- More time for learning stable equilibrium
- Proper termination signals instead of timeout-before-fall

### 2. Knee Height: Progressive → Optimal Range

**Old reward**: `knee_height_above_threshold`
- Progressive: more height = more reward
- Encouraged unlimited height increase
- Led to unstable, excessive lifting

**New reward**: `knee_height_optimal_range`
- Target zone: 0.25m - 0.40m (optimal single-leg stance)
- Penalty above 0.45m (too high = unstable)
- Encourages moderate, stable lift

## Knee Height Reward Function

```python
def knee_height_optimal_range(
  env,
  min_height=0.20,      # Minimum to be considered "lifted"
  optimal_height=0.30,  # Sweet spot for stability
  max_height=0.45,      # Above this = penalty
)
```

### Reward Curve

| Height (m) | Normalized Reward | Total (×3.0) | Interpretation |
|------------|-------------------|--------------|----------------|
| 0.00 | 0.00 | 0.00 | Not lifting |
| 0.10 | 0.15 | 0.45 | Starting to lift |
| 0.20 | 0.30 | 0.90 | Min threshold |
| 0.25 | 0.65 | 1.95 | Ramping up |
| **0.30** | **1.00** | **3.00** | **✓ OPTIMAL!** |
| **0.35** | **1.00** | **3.00** | **✓ OPTIMAL!** |
| **0.40** | **1.00** | **3.00** | **✓ Still good** |
| 0.45 | 0.50 | 1.50 | Getting high |
| **0.50** | **-0.50** | **-1.50** | **TOO HIGH (penalty)** |
| **0.60** | **-2.50** | **-7.50** | **WAY TOO HIGH** |

### Reward Regions

```
Region 1 (0.0 - 0.20m): Small reward for any lifting
  reward = 0.3 * (height / 0.20)
  
Region 2 (0.20 - 0.30m): Ramping to optimal
  reward = 0.3 + 0.7 * ((height - 0.20) / 0.10)
  
Region 3 (0.30 - 0.40m): OPTIMAL ZONE - maximum reward
  reward = 1.0
  
Region 4 (0.40 - 0.45m): Gentle decay
  reward = 1.0 - 0.5 * ((height - 0.40) / 0.05)
  
Region 5 (>0.45m): PENALTY ZONE
  reward = 0.5 - 2.0 * (height - 0.45)
```

## Why This Works

### Problem with Progressive Height
```
Robot logic: "More height = more reward"
→ Lifts knee as high as possible (0.6m+)
→ Extremely unstable
→ Falls over
→ Never learns stable stance
```

### Solution with Optimal Range
```
Robot logic: "0.30m gives maximum reward, 0.60m gives penalty"
→ Learns to lift to ~0.30-0.35m
→ Stable, moderate lift
→ Can maintain balance
→ Gets duration rewards
```

## Implementation Details

### Knee Height Calculation

```python
# Find knee body indices from robot model
body_names = [body.name for body in asset.indexing.bodies]
left_knee_idx = body_names.index("left_knee_link")
right_knee_idx = body_names.index("right_knee_link")

# Get knee positions
left_knee_pos = asset.data.body_link_pose_w[:, left_knee_idx, :3]
right_knee_pos = asset.data.body_link_pose_w[:, right_knee_idx, :3]

# Get standing foot height
left_foot_pos = asset.data.sensor_data["left_foot_ground_contact"][:, 1:4]
right_foot_pos = asset.data.sensor_data["right_foot_ground_contact"][:, 1:4]

# Calculate raised knee height relative to standing foot
standing_foot_z = select_by_standing_leg(left_foot_pos[:, 2], right_foot_pos[:, 2])
raised_knee_z = select_by_standing_leg(right_knee_pos[:, 2], left_knee_pos[:, 2])
knee_height = raised_knee_z - standing_foot_z
```

## Expected Training Behavior

### Early Training (0-200k steps)
- Robot learns weight shift (weight_shift_preparation: 0 → 4.0)
- Discovers foot lifting (foot_clearance: 0 → 5.0)
- Knee height starts growing

### Mid Training (200k-500k steps)
- **Old**: Knee height keeps increasing (0.3 → 0.5 → 0.7m), robot falls
- **New**: Knee height converges to 0.25-0.35m, robot stable!

### Late Training (500k+ steps)
- `knee_height_optimal_range`: Stable ~2.5-3.0 reward (0.30m height)
- `balanced_stance_duration`: Growing steadily
- Robot maintains stable single-leg stance

## Comparison: v5.0 vs v5.1

| Feature | v5.0 | v5.1 |
|---------|------|------|
| **Episode Length** | 20s | **40s** |
| **Max Steps** | 1000 | **2000** |
| **Knee Height Reward** | Progressive (unlimited) | **Optimal range (0.25-0.40m)** |
| **Height >0.45m** | Still rewarded | **Penalized** |
| **Reward Name** | `knee_height` | **`knee_height_optimal_range`** |
| **Weight** | 3.0 | **3.0** (same) |

## Full Reward Structure (v5.1)

```
STAGE 1 - Weight Shift (4.0):
├── weight_shift_preparation: 4.0

STAGE 2 - Initial Lift (5.0):
├── foot_clearance: 5.0

STAGE 3 - Optimal Height + Duration (7.0):
├── knee_height_optimal_range: 3.0  ← CHANGED!
└── balanced_stance_duration: 4.0

CONDITIONAL - Only when foot up (2.0):
└── conditional_upright: 2.0

AUXILIARY (0.2):
└── alive: 0.2

PENALTIES (-0.72):
├── orientation_penalty: -0.5
├── base_angular_penalty: -0.02
├── action_rate: -0.002
└── joint_limits: -0.2
```

**Total positive**: 18.2 (same as v5.0)
**Penalties**: -0.72 (same)

## Training Command

```bash
MUJOCO_GL=egl uv run train Mjlab-Balancing-Flat-Unitree-G1 --env.scene.num-envs 4096
```

## Monitoring Metrics

**Success Indicators**:
1. `knee_height_optimal_range`: Should converge to ~2.5-3.0 (not keep increasing)
2. Episode length: Should approach 40s (not timeout at 20s)
3. `fell_over` termination: Should trigger if robot is actually falling
4. `balanced_stance_duration`: Should grow steadily (robot sustaining pose)

**Red Flags**:
- `knee_height_optimal_range` becomes negative: Robot lifting too high, getting penalties
- Episodes still timeout quickly: Increase episode length further
- Robot not lifting at all: Check `foot_clearance` and `weight_shift_preparation` rewards

## Summary

**v5.1 = Stable Single-Leg Stance**

1. ✅ **40s episodes**: Time to reach and maintain stable position
2. ✅ **Optimal height target**: 0.25-0.40m (moderate, stable lift)
3. ✅ **Penalties for excess**: >0.45m penalized to prevent instability
4. ✅ **All other rewards unchanged**: Weight shift, foot clearance, duration, etc.

The robot will now learn to lift its foot to a **moderate, stable height** (~0.30m) rather than maximizing height, which should result in a much more stable single-leg stance!


